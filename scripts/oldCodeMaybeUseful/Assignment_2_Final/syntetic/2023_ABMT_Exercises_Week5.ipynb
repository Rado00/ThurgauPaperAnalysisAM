{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea Behind This Exercisie\n",
    "\n",
    "The aim of this lab is to give you the tools to read and analyze MATSim results. The library used ([matsim-tools](https://github.com/matsim-vsp/matsim-python-tools)) also provides basic utilities to write MATSim files, which might be useful if you want to modify the input files for your project.\n",
    "\n",
    "Generating maps and analyses in python or another scripting languages has a few advantages compared to an interactive program, such as VIA:\n",
    "- it is much more configurable, and in particular makes it quite easy to make comparison between various runs or parts of the day\n",
    "- by being a script, it can easily be ran for multiple runs\n",
    "\n",
    "Where VIA shines is interactive analysis, and in particular visualization of movement, rather than aggregate quantities.\n",
    "\n",
    "Make sure that you install the required packages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For this class we would need the matsim-tools package and contextily, so you need to pip install it if you haven't already. See below\n",
    "\n",
    "!pip install matsim-tools\n",
    "\n",
    "!pip install contextily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matsim\n",
    "import os\n",
    "import contextily as ctx\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/cluster/home/salathem/Programming/data'\n",
    "scenario_path = data_folder + '/scenarios/Zurich/10pct'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network\n",
    "\n",
    "This section does not contain any exercise, but demonstrates how to read in and visualize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This reads in the network in a structure that contains two tables, one for links and one for nodes.\n",
    "network = matsim.read_network(os.path.join(scenario_path, \"zurich_network.xml.gz\"))\n",
    "\n",
    "# this creates a geographic dataframe\n",
    "network_geo = network.as_geo('epsg:2056')\n",
    "network_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geopandas (the library providing geographic dataframes) provides methods to easily plot geographic data\n",
    "# the network contains lots of links that represent the public transport connections. In the scenario we use,\n",
    "# all road links have mode \"car,car_passenger\"\n",
    "network_geo.query('modes == \"car,truck,car_passenger\"').plot(\n",
    "    column=\"freespeed\",\n",
    "    figsize=(15,15),\n",
    "    legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The network contains information about the coordinate system it is expressed in, which is useful eg. to add map backgrounds\n",
    "network_geo.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = network_geo.query('modes == \"car,truck,car_passenger\"').plot(\n",
    "    column=\"freespeed\",\n",
    "    figsize=(15,15),\n",
    "    legend=True)\n",
    "\n",
    "# it is possible to focus the plot on an area of interest\n",
    "ax.set_xlim((2.66e6, 2.72e6))\n",
    "ax.set_ylim((1.22e6, 1.27e6))\n",
    "\n",
    "# contextily provides an easy way to add a map background, useful to get context\n",
    "ctx.add_basemap(ax=ax, crs=network_geo.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plan reader gives an iterator over the plans in the file\n",
    "# It actually just provides a way to iterate over the XML elements\n",
    "plans = matsim.plan_reader(os.path.join(scenario_path, \"zurich_population_10pct.xml.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"next\" provides one element of the iterator, which we use here to look at how the elements look like.\n",
    "# The typical way to use an iterator is in a for loop (see below)\n",
    "first_person, first_plan = next(plans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrib provides the attributes of the tag, in the XML sense\n",
    "first_person.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_plan.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags that contains elements, such as the plan, are also iterable\n",
    "list(first_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of how to create a dataframe with activities\n",
    "plans = matsim.plan_reader(os.path.join(scenario_path, \"zurich_population_10pct.xml.gz\"))\n",
    "records = []\n",
    "for person, plan in plans:\n",
    "    person_id = person.attrib['id']\n",
    "    for plan_element in plan:\n",
    "        if plan_element.tag == 'activity':\n",
    "            records.append({\n",
    "                'id': person_id,\n",
    "                'x': float(plan_element.attrib['x']),\n",
    "                'y': float(plan_element.attrib['y']),\n",
    "                'type': plan_element.attrib['type']\n",
    "            })\n",
    "activities = pd.DataFrame.from_records(records)\n",
    "activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform into a geographic dataframe\n",
    "activities_geo = gpd.GeoDataFrame(\n",
    "    activities,\n",
    "    geometry=gpd.points_from_xy(activities.x, activities.y),\n",
    "    crs=network_geo.crs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax=activities_geo.plot(column=\"type\", figsize=(15,15), legend=True, alpha=0.1)\n",
    "ctx.add_basemap(ax, crs=activities_geo.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events\n",
    "\n",
    "The events are the trace of everything that happens in the simulated physical world, and can be used to produce all kind of analyses. It can be read in a way similar to the plans file.\n",
    "\n",
    "Events files are typically very big, and it is thus often a good idea to aggregate the information while reading the file. This is demonstrated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Events in Siouxfall\n",
    "\n",
    "events = matsim.event_reader(\n",
    "    data_folder + '/output/output-siouxfalls/output_events.xml.gz',\n",
    "    # the reader offers a filter of event types for performance.\n",
    "    # we will parse the file once and extract two tables: traffic counts over per half-day and mode of transport of departures per link\n",
    "    types='left link,departure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaultdict creates a value if not there. Here, it creates the default int, which is 0\n",
    "link_counts = defaultdict(int)\n",
    "departure_counts = defaultdict(int)\n",
    "\n",
    "# function to identify the time period based on time of day\n",
    "def time_period(time_s):\n",
    "    if time_s < 12 * 3600:\n",
    "        return \"morning\"\n",
    "    return \"afternoon\"\n",
    "\n",
    "# iterate through all the events. This takes a little while\n",
    "for event in events:\n",
    "    # as for the population, the objects reflect the structure of the XML file\n",
    "    period = time_period(event[\"time\"])\n",
    "    link = event[\"link\"]\n",
    "    \n",
    "    if event[\"type\"] == \"left link\":\n",
    "        link_counts[(link, period)] += 1\n",
    "    if event[\"type\"] == \"departure\":\n",
    "        mode = event[\"legMode\"]\n",
    "        departure_counts[(link, period, mode)] += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(link_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(departure_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# transform collected data into a data frame\n",
    "count_table = pd.DataFrame.from_records([\n",
    "    {'link_id': link, 'period': period, 'link_count': link_count}\n",
    "    for (link, period), link_count in link_counts.items()\n",
    "])\n",
    "\n",
    "#Load siouxfall network file\n",
    "# This reads in the network in a structure that contains two tables, one for links and one for nodes.\n",
    "network = matsim.read_network(data_folder + \"/scenarios/SiouxFalls/Siouxfalls_network_PT.xml\")\n",
    "\n",
    "# this creates a geographic dataframe\n",
    "network_geo = network.as_geo()\n",
    "# merge with network data to be able to produce maps\n",
    "count_table = network_geo.merge(count_table, on='link_id')\n",
    "count_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot counts for the morning period\n",
    "ax=count_table.query(\"period == 'morning'\").plot(column=\"link_count\", figsize=(15,15), legend=True, cmap=\"Reds\")\n",
    "ax.set_xlim((679000, 687000))\n",
    "ax.set_ylim((4.820e6, 4.832e6))\n",
    "ctx.add_basemap(ax, crs=count_table.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: plot difference in traffic counts between morning and afternoon period\n",
    "\n",
    "Use the data collected from the events to plot a map of the difference of traffic in the two time periods.\n",
    "You are free to choose the method you prefer, but here are two suggestions:\n",
    "- use the \"pivot\" function (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html#pandas.DataFrame.pivot)\n",
    "- split the count table in two tables, one per period, and re-merge them based on the link id. This would emulate how you would do it to compare separate runs, compared to values from the same run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "antEnv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e844146b4402922edc282834f163f9a0d641b235707d4d6937c70f86c82d4552"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
